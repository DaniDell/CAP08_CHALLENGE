# 🚀 Proyecto de API Inteligente con FastAPI, OpenAI y Machine Learning

Bienvenido a este proyecto que integra procesamiento de lenguaje natural, generación de texto, machine learning y APIs de alto rendimiento.  
Construido con **FastAPI**, **OpenAI API**, **Langchain** y otras tecnologías modernas.

## 📦 Tecnologías principales

- **FastAPI** – Framework web asíncrono rápido para construir APIs.
- **OpenAI** – Integración con modelos de lenguaje (GPT-4, GPT-3.5).
- **Langchain** – Framework para construir aplicaciones inteligentes con LLMs.
- **Redis** – Base de datos en memoria para cacheo rápido.
- **Pandas** – Manejo y análisis de datos tabulares.
- **Scikit-Learn** – Machine Learning clásico para clasificación, clustering, etc.
- **Spacy** – Procesamiento de lenguaje natural (NLP).
- **BeautifulSoup4** – Scraping de contenido HTML.
- **Uvicorn** – Servidor ASGI ultrarrápido para producción.

## 🚀 Cómo levantar el proyecto localmente

1. Clona este repositorio:
   ```bash
   git clone https://github.com/tu_usuario/tu_repo.git
   cd tu_repo
   ```

2. Crea y activa un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows usa: venv\Scripts\activate
   ```

3. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Crea un archivo `.env` en la raíz del proyecto para configurar tus variables de entorno:
   ```
   OPENAI_API_KEY=tu-clave-api-openai
   REDIS_URL=redis://localhost:6379
   ```

5. Corre el servidor de desarrollo:
   ```bash
   uvicorn app.main:app --reload
   ```

---

## 📂 Estructura del proyecto

```bash
📁 app/
    ├── main.py         # Punto de entrada de la API
    ├── routers/        # Rutas organizadas por módulos
    ├── services/       # Lógica de negocio (integraciones, procesamiento)
    ├── models/         # Modelos de datos (Pydantic)
    ├── utils/          # Utilidades auxiliares
    └── config/         # Configuración de variables de entorno
📄 requirements.txt
📄 README.md
📄 .env.example
```

---

## ✅ Funcionalidades previstas

- [x] API RESTful moderna y documentada automáticamente (Swagger / Redoc).
- [x] Integración de modelos de lenguaje (GPT) vía OpenAI API.
- [x] Consultas inteligentes con Langchain.
- [x] Machine Learning clásico con Scikit-Learn.
- [x] Cache de respuestas usando Redis.
- [x] Scraping básico de datos para alimentar modelos.
- [ ] (Próximamente) Implementación de pipelines de entrenamiento y fine-tuning.

---

## 📚 Requerimientos

- Python 3.10+
- Redis instalado y corriendo localmente o en un servidor
- Cuenta en OpenAI para obtener API Keys

---

## 🤝 Contribuciones

¡Las contribuciones son bienvenidas!  
Puedes abrir issues o enviar pull requests para mejorar o expandir el proyecto.

---

## 📄 Licencia

Este proyecto está bajo licencia MIT.

---

¿Quieres que también te genere un archivo `requirements.txt` basado en la lista que me pasaste?  
Así tendrías ya el pack completo para empezar 🚀.

## 🌐 Flujo de búsqueda en internet

El siguiente diagrama muestra cómo funciona el flujo de búsqueda en internet dentro del proyecto. Desde que el usuario realiza una consulta hasta que se genera una respuesta enriquecida con datos externos.

## 🌐 Flujo de búsqueda en internet

El siguiente diagrama muestra cómo funciona el flujo de búsqueda en internet dentro del proyecto. Desde que el usuario realiza una consulta hasta que se genera una respuesta enriquecida con datos externos.

```mermaid
graph TD
    A[Usuario] -->|Consulta al endpoint /chat| B[FastAPI]
    B -->|Llama a search_google| C[search_google - API de Google]
    C -->|Realiza una solicitud HTTP| D[Google Custom Search API]
    D -->|Devuelve resultados JSON| C
    C -->|Procesa resultados| E[process_search_results_with_content]
    E -->|Limpia y enriquece datos| F[fetch_page_content]
    F -->|Obtiene contenido adicional de las páginas web| G[BeautifulSoup]
    G -->|Devuelve contenido limpio| E
    E -->|Resultados procesados| H[Langchain]
    H -->|Genera respuesta con contexto| I[Respuesta final al usuario]