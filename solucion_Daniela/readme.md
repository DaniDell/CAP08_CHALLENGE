# ðŸš€ Proyecto de API Inteligente con FastAPI, OpenAI y Machine Learning

Bienvenido a este proyecto que integra procesamiento de lenguaje natural, generaciÃ³n de texto, machine learning y APIs de alto rendimiento.  
Construido con **FastAPI**, **OpenAI API**, **Langchain** y otras tecnologÃ­as modernas.

## ðŸ“¦ TecnologÃ­as principales

- **FastAPI** â€“ Framework web asÃ­ncrono rÃ¡pido para construir APIs.
- **OpenAI** â€“ IntegraciÃ³n con modelos de lenguaje (GPT-4, GPT-3.5).
- **Langchain** â€“ Framework para construir aplicaciones inteligentes con LLMs.
- **Redis** â€“ Base de datos en memoria para cacheo rÃ¡pido.
- **Pandas** â€“ Manejo y anÃ¡lisis de datos tabulares.
- **Scikit-Learn** â€“ Machine Learning clÃ¡sico para clasificaciÃ³n, clustering, etc.
- **Spacy** â€“ Procesamiento de lenguaje natural (NLP).
- **BeautifulSoup4** â€“ Scraping de contenido HTML.
- **Uvicorn** â€“ Servidor ASGI ultrarrÃ¡pido para producciÃ³n.

## ðŸš€ CÃ³mo levantar el proyecto localmente

1. Clona este repositorio:
   ```bash
   git clone https://github.com/tu_usuario/tu_repo.git
   cd tu_repo
   ```

2. Crea y activa un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows usa: venv\Scripts\activate
   ```

3. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Crea un archivo `.env` en la raÃ­z del proyecto para configurar tus variables de entorno:
   ```
   OPENAI_API_KEY=tu-clave-api-openai
   REDIS_URL=redis://localhost:6379
   ```

5. Corre el servidor de desarrollo:
   ```bash
   uvicorn app.main:app --reload
   ```

---

## ðŸ“‚ Estructura del proyecto

```bash
ðŸ“ app/
    â”œâ”€â”€ main.py         # Punto de entrada de la API
    â”œâ”€â”€ routers/        # Rutas organizadas por mÃ³dulos
    â”œâ”€â”€ services/       # LÃ³gica de negocio (integraciones, procesamiento)
    â”œâ”€â”€ models/         # Modelos de datos (Pydantic)
    â”œâ”€â”€ utils/          # Utilidades auxiliares
    â””â”€â”€ config/         # ConfiguraciÃ³n de variables de entorno
ðŸ“„ requirements.txt
ðŸ“„ README.md
ðŸ“„ .env.example
```

---

## âœ… Funcionalidades previstas

- [x] API RESTful moderna y documentada automÃ¡ticamente (Swagger / Redoc).
- [x] IntegraciÃ³n de modelos de lenguaje (GPT) vÃ­a OpenAI API.
- [x] Consultas inteligentes con Langchain.
- [x] Machine Learning clÃ¡sico con Scikit-Learn.
- [x] Cache de respuestas usando Redis.
- [x] Scraping bÃ¡sico de datos para alimentar modelos.
- [ ] (PrÃ³ximamente) ImplementaciÃ³n de pipelines de entrenamiento y fine-tuning.

---

## ðŸ“š Requerimientos

- Python 3.10+
- Redis instalado y corriendo localmente o en un servidor
- Cuenta en OpenAI para obtener API Keys

---

## ðŸ¤ Contribuciones

Â¡Las contribuciones son bienvenidas!  
Puedes abrir issues o enviar pull requests para mejorar o expandir el proyecto.

---

## ðŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT.

---

Â¿Quieres que tambiÃ©n te genere un archivo `requirements.txt` basado en la lista que me pasaste?  
AsÃ­ tendrÃ­as ya el pack completo para empezar ðŸš€.

## ðŸŒ Flujo de bÃºsqueda en internet

El siguiente diagrama muestra cÃ³mo funciona el flujo de bÃºsqueda en internet dentro del proyecto. Desde que el usuario realiza una consulta hasta que se genera una respuesta enriquecida con datos externos.

## ðŸŒ Flujo de bÃºsqueda en internet

El siguiente diagrama muestra cÃ³mo funciona el flujo de bÃºsqueda en internet dentro del proyecto. Desde que el usuario realiza una consulta hasta que se genera una respuesta enriquecida con datos externos.

```mermaid
graph TD
    A[Usuario] -->|Consulta al endpoint /chat| B[FastAPI]
    B -->|Llama a search_google| C[search_google - API de Google]
    C -->|Realiza una solicitud HTTP| D[Google Custom Search API]
    D -->|Devuelve resultados JSON| C
    C -->|Procesa resultados| E[process_search_results_with_content]
    E -->|Limpia y enriquece datos| F[fetch_page_content]
    F -->|Obtiene contenido adicional de las pÃ¡ginas web| G[BeautifulSoup]
    G -->|Devuelve contenido limpio| E
    E -->|Resultados procesados| H[Langchain]
    H -->|Genera respuesta con contexto| I[Respuesta final al usuario]